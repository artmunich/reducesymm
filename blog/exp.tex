% siminos/blog/exp.tex
% $Author$ $Date$

\chapter{Symmetry reduction of experimental data}
\label{c-exp}

\begin{bartlett}{
I'm a slicing disciple now.
}
\bauthor{
Michael Schatz, March 3 2012
    }
\end{bartlett}



\begin{description}

\item[2011-08-12 Predrag] Woods Hole Geophysical Fluid Dynamics Program
report: After describing in
\HREF{http://chaosbook.org/overheads/continuous/index.html}{my seminar}
the \mslices, I talked to experimentalists
\HREF{http://www.mcnd.manchester.ac.uk/mullin.html}{Tom Mullin}
and
\HREF{https://www.irphe.fr/~legal/}{Patrice Le Gal}
(who studies instabilities and transitions of rotor-stator flows) about
implementing numerically the `nearest group orbit point' distance for
\emph{experimental} video images of flows. Experimentally collecting the
full 3D velocity vector field information is not feasible, but as the
physical dimension of the inertial manifold for transitional
boundary-shear flows in a minimal cell might be as low as 100 to 1,000
dimensions, well constructed projections from 100,000 to
1,000,000-dimensional \statesp s might capture the topology and correctly
identify the nearest neighbors. In the fluids community everybody worries
about choices of `norms', especially the control engineers who have to
optimize perturbations in order to attain desired ends. People agree that
there is no compelling reason to use the energy norm, other than that
velocity fields is what is given in a numerical computation. For example,
in the study of `optimal perturbations' that move a laminar solution to a
turbulent one, both energy\rf{TeHaHe10} and dissipation\rf{LoCaCoPeGo11}
norms have been used.

My first thought has been to define a Gaussian-smeared out norm to
compare Hamming (pixel by pixel) distance between two images, smearing
being necessary to account for the sensor noise. Problem is that for
nonlinear flows this noise should not be isotropic\rf{LipCvi08,LipCvi07}
- it matters whether points compared are on unstable or stable manifolds,
etc. But as this is a pattern recognition problem, why not use the
accumulated wisdom of the pattern compression and pattern recognition
community?

\end{description}

\section{A letter to our experimental friends}

    \PC{
    edits: {\bf 2011-08-12}, {\bf 2012-01-03}
    }
A modest proposal: jpeg and gif algorithms are optimized to reduce the
information content of an image. Optimization is for human vision, but
that might be OK for our purposes. So use not the raw, but the jpeg
compressed images, their [pixel$\times$pixel] size reduced to the
resolution realistically needed, each pixel a coordinate in the \statesp\
(if the proposal works, in later stages one might actually want to go
into the jpeg algorithm and start tweaking its parameters). The group
orbit is traced in this \statesp\ by translating a given image. For
example, in Le Gal's `French washing machine' experiments, or Mullin's
expanding pipe ones, the group orbit is traced out by rotating a given
image around the rotation axis, and the group tangent at a given image is
obtained by a minute angular rotation of a pattern. Pick a state of the
fluid that seems important and typical of the flow studies, and us it a
template. Its group tangent defines the slice hyperplane, and its group
curvature (the second derivative of the group orbit with respect to the
angle) both defines the \sset\ (the outer edges of the neighborhood that
can be associated with a given template), and an optimal coordinate to
project the group orbit and visualize it in a 2\dmn\ projection. The
dynamics in the slice is determined by step-by-step post-processing, \ie,
by finding the angle that satisfies the slice-group tangent
orthogonality, and rotating the full \statesp\ trajectory into the slice.
This symmetry reduction is lossless: it \emph{loses no information},
other than what was lost in going from the raw image to the jpeg
compressed image.

From the theoretical/numerical studies of flows with symmetries%
\rf{SCD07,ACHKW11}
we have learned that the reduced dynamics can be visualized in two ways:

\begin{enumerate}
\item Make a video from the slice reduced video frames; in such video a
radially symmetric spiral pattern becomes a stationary \reqv\ (again, no
information lost - \emph{this is not averaging over the azimuthal
angle}), and turbulence reduces to turbulence with azimuthal drifts
removed.

Beyn\rf{BeTh04} calls this `freezing.' To understand why they call it
`freezing' the figures are useful, and especially the animations, like
\HREF{http://www.mathematik.uni-bielefeld.de/fgweb/Preprints/movies/fg03022_02.mpg}
{this one}. Of course, a turbulent state will not be 'frozen,' but much
of the hysterical fast drifting will be gone.

    \item Project the \statesp\ trajectory on 2-3 coordinates formed from
dynamically important states of the fluid\rf{GHCW07}. There things like
bifurcation of a spiral in two spirals, or bifurcation of a torus into
two tori will be reduced to the garden variety dynamical systems
bifurcations.

    \item More importantly, experimental dynamics will reveal swirls and
close passages to invariant solutions that \emph{cannot} be discerned from the
symmetry-unreduced flow.

    \item The connection to numerics is now made by generating jpegs of
numerical flows visualized from the same vantage point as that of the camera
shooting the experimental flow. Once a nearby image is identified in the
numerical flow, one can run numerics to predict the future evolution, and
compare it with experimental flow, using Kalman filter data assimilation
to keep the numerical prediction close to the observed state of the
fluid.
\end{enumerate}

\section{Discussion}

\begin{description}

\item[2012-02-22 Predrag]
If the norm $\braket{y}{x}$ is defined as some pixel - to pixel distance,
what trouble are we to expect from the fact we are measuring distance
only on the subset of dimensions of the full PDE problem? In the energy
norm we use the full velocity field to measure distances; in this
proposal we use a subset that is captured by experimental camera. No
idea...

\item[2011-12-23 Bj\"orn]
About slicing, sure it would be great to do this with experimental data.
In pipes we typically do not have the time information. Even with
simple flow visualization images we typically look at a few
diameters in length (fixed in the lab frame) and turbulence advects past.
I guess we would have to visualize long sections for slicing to have the
necessary time information?

Something else which may be useful: we recently managed to converge
experimental velocity fields with the Newton method to TW solutions. What
we did is we took our experimental velocity data, stagger the
cross-sections together (i.e. convert time to space by using Taylor's
hypothesis) and then feed the 3D structure. Have a look at
\refref{deLMeAvHo12} (Predrag put a copy into the ChaosBook.org/library,
\HREF{http://ChaosBook.org/library/deLMeAvHo12.pdf}{click here}).  One
case is in there (figures 2 and 3). We just tried a second case (we only
tried two cases so far) and it converged to another traveling wave (to the
symmetric version of the one in the paper, which is also on the edge). For
numerical people it may not be too extraordinary to converge something
with Newton but for experiments I did not expect this would ever work. We
will try this with turbulent data (i.e. non decaying) next.

We have also made progress with this volumetric PIV technique. We can now
measure the full velocity field in a volume about one diameter streamwise
(this gives us some time information).

How about if we use a mixed experimental and numerical strategy? We could
use whatever velocity data we get from experiments (preferably 3D in a
volume) and get further time information from time stepping this in a
numerical code and then do the slicing???

I will discuss further slicing possibilities in experiments with Marc.

\item[2012-01-02 Bj\"orn]
Further thoughts about slicing experimental data. I am still in favor of
doing this with velocity data rather than flow visualization images.

What is easy for us to do is to measure cross sections with all three
velocity components (like in the 2004 Science paper). If we do this fully
time resolved we can get about 100 D/U time units continuous data with
one measurement (after that the camera memory is full). The
difficulty is that the information we get is the evolution in space
rather than in time, \ie, we sample turbulent structures as they
are advected through our measurement cross section. But possibly this is
not a problem for the slicing technique and we can just ignore this to
some extent (??).

If that is the case I suggest the following procedure: We take the 100 D/U
velocity data, and put a window of lets say 2.5 D over it. Inside this
2.5 D window we pretend turbulence is frozen in time, which gives us the
3D spatial information. Then we move this window across our data set
which gives us the time information.

Basically this way we get turbulence in a short BUT non-periodic pipe.

Could we do slicing with this? I would think that with this we can
probably identify traveling waves but I do not see how we could find
\rpo s, for which we would need the time information.

\item[2012-01-09 Bj\"orn]
Let me try to simplify what I meant: In the experiment we are lacking
periodic boundary conditions and turbulence advects past. Now if we
assume that coherent structures in the experiment are short (at  the
most we found one or two wavelength) then we cannot see a full
oscillation period either. The structure will have disappeared downstream
before a full period has passed.

\item[2012-02-27 Predrag] There is much pattern recognition literature
using Lie groups, potentially relevant to this, see for example
\refrefs{BayOrt04,DruCip00}.

\item[2012-02-27 Mike] Here we have a simulation of 2\dmn\ turbulence;
Radford simulates it, and we see it experimentally. How am I to slice
such videos?

\item[2012-03-01 Predrag] What is striking about your data, and many
other simulations is that I have seen (baroclinic instability, cardiac
spiral chaos) is that the aspect ratio is rather large, so you have many
vortex structure coexisting. There is no good template for a whole crowd
- imagine you are taking a group portrait of conference participants.
Trying to find distance to a template of 112 people that fits a
particular arrangement of actual people would be crazy. What face
recognition software does is to define a norm that is large only on a
scale of a single face, and suppressed a few people distances away; then
one uses the approximate Euclidean and scaling invariance to orient and
bring the face into proximity of your template of a face, not a snapshot
of a crowd in a night club.

What handwriting and voice recognition software does is then to track the
object of interest in time for a while. That is much more powerful than a
stationary snapshot, and that is what templates in dynamical systems are
- videos, not just snapshots.

For large aspect systems I imagine we fit local templates whose 2\dmn\
or 3\dmn\ volume is concentrated on a region big enough to capture
interaction of close-by structures, but small enough not to track weakly
interacting ones.

In other words, cover 3\dmn\ volume with a finite-size template that
tracks a neighborhood for a finite time. It's OK to make it spatially
periodic, as long as distance is measured in finite size spatio-temporal
windows. That is what we already do when we use unstable \po s - we use
infinitely temporally periodic solution (that cannot be seen in
experiment) to identify a finite-time neighboring segment of a chaotic
trajectory.

It has not been tried, so I might be wrong (again).

\item[2012-03-01 CNS slicing pow-pow] Mike is optimistic, Roman is
dismissive (and clueless), Predrag is sure slicing is the right thing to
do. Rest said not a word.

\item[2012-03-02 Mike] (on my birthday):
I'm slicing away on 2d turbulence.   We can chat about it next week.

\item[2012-03-04 Predrag] Yippee, I got a 4th convert, and the first
experimental convert:

\item[2012-03-04 Mike]
A first pass with \statesp\ slicing of 2D turbulence (Radford's
simulation data) yielded some surprises.  It was pretty easy, too...
starting from scratch, it took about 3 hours. However, I only sliced the
continuous symmetry in the problem... I didn't slice the discrete
symmetry yet because I skipped too many of your classes. Nevertheless, I
think I know what to do ... It will take another 30 min or so that I
don't have now.  I can show you the results tomorrow or Tuesday. it's
pretty informative and there are some surprises.  (Bala and Roman, even
though you saw some of the projection results on Saturday; the slicing
results will be new for you, too.)

\item[2012-03-04 Predrag] For the discrete symmetry, need to know whether it is
rotation by $\pi$ or a parity operation (they differ by the sign of the
determinant of the operation). Should be the easier part.

\item[2012-03-04 Roman] I think it is better to form the global basis by
using the base state and its images under discrete symmetry operations,
i.e., half-period $y$-shift and the 180 degree rotation. The half-period
$x$-shift is a particular group member from a continuous symmetry group and
so will symmetry-reduced leading to a degeneracy.

Predrag will correct me, if I am wrong.

\item[2012-03-05 Predrag] Not sure what 'the base state' is - something like
the upper branch Gibson and I use to construct \statesp\ projections for \pCf?
Anyway, let's talk about it.


\end{description}
